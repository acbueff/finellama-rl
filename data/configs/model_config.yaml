# FineMath model configuration

# Model identification
model_name_or_path: "SunnyLin/Qwen2.5-7B-DPO-VP"  # Using Qwen2.5 model
model_type: "qwen"
use_auth_token: true  # Use token for access

# Model parameters
max_length: 2048  # Maximum sequence length
generation_max_length: 512  # Maximum generation length for inference
pad_token_id: 0
eos_token_id: 1
use_fast_tokenizer: true

# Optimization settings
bf16: true  # Use bfloat16 precision if available
fp16: false  # Use fp16 precision if bf16 is not available
gradient_checkpointing: true  # Enable gradient checkpointing to save memory

# Quantization and efficiency settings
load_in_8bit: false  # Whether to load model in 8-bit precision
load_in_4bit: true  # Whether to load model in 4-bit precision
use_peft: true  # Whether to use Parameter-Efficient Fine-Tuning

# PEFT Configuration (if use_peft is true)
peft_config:
  peft_type: "lora"  # LoRA adapter type
  task_type: "CAUSAL_LM"
  r: 16  # LoRA attention dimension
  lora_alpha: 32  # LoRA alpha parameter
  lora_dropout: 0.05  # Dropout probability for LoRA layers
  target_modules: ["q_proj", "v_proj", "k_proj", "o_proj"]  # Modules to apply LoRA to
  bias: "none"  # Whether to train bias parameters

# Decoding parameters
do_sample: true
temperature: 0.7
top_p: 0.9
top_k: 50
num_beams: 1  # Use 1 for greedy, >1 for beam search
repetition_penalty: 1.1

# Trust remote code
trust_remote_code: true  # Needed for Qwen models

# Specialized for math
math_special_tokens: true  # Enable special tokens for math operations 
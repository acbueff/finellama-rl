Bootstrap: docker
From: pytorch/pytorch:2.3.0-cuda12.1-cudnn8-devel

%environment
    export LC_ALL=C
    export PATH="/opt/conda/bin:$PATH"
    export CUDA_HOME="/usr/local/cuda"
    export LD_LIBRARY_PATH="/usr/local/cuda/lib64:$LD_LIBRARY_PATH"

%post
    apt-get update && apt-get install -y --no-install-recommends \
        git \
        curl \
        vim \
        wget \
        build-essential \
        ca-certificates \
        libjpeg-dev \
        libpng-dev \
        libopenblas-dev \
        && rm -rf /var/lib/apt/lists/*
    
    # Ensure CUDA environment is properly set
    echo 'export CUDA_HOME="/usr/local/cuda"' >> /etc/bash.bashrc
    echo 'export PATH="/usr/local/cuda/bin:$PATH"' >> /etc/bash.bashrc
    echo 'export LD_LIBRARY_PATH="/usr/local/cuda/lib64:$LD_LIBRARY_PATH"' >> /etc/bash.bashrc
    
    # Install Python dependencies
    pip install --no-cache-dir --upgrade pip
    pip install --no-cache-dir \
        transformers==4.51.3 \
        datasets \
        accelerate \
        peft \
        sentencepiece \
        scikit-learn \
        tensorboard \
        evaluate \
        bitsandbytes \
        deepspeed \
        protobuf \
        rouge-score \
        fire \
        pyarrow \
        safetensors \
        scipy
    
    # Install TRL version 0.16.1 specifically
    pip install --no-cache-dir trl==0.16.1
    
    # Install flash-attn with CUDA support
    export CUDA_HOME="/usr/local/cuda"
    export PATH="/usr/local/cuda/bin:$PATH"
    pip install --no-cache-dir flash-attn --no-build-isolation
    
    # Clean up
    apt-get clean
    rm -rf /var/lib/apt/lists/*
    pip cache purge

%runscript
    exec python "$@"

%labels
    Author x_anbue
    Version 1.0
    Description Container with PyTorch, TRL, and flash-attn for ML experiments 